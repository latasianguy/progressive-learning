{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LifelongClassificationForest' from 'proglearn.progressive_learner' (C:\\Users\\shizh\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\proglearn-0.0.3-py3.7.egg\\proglearn\\progressive_learner.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-6bc610c4c567>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlog2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mproglearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogressive_learner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProgressiveLearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLifelongClassificationForest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mproglearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeciders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleArgmaxAverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKNNClassificationDecider\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mproglearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTreeClassificationTransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNeuralClassificationTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LifelongClassificationForest' from 'proglearn.progressive_learner' (C:\\Users\\shizh\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\proglearn-0.0.3-py3.7.egg\\proglearn\\progressive_learner.py)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from math import log2, ceil\n",
    "from proglearn.progressive_learner import ProgressiveLearner, LifelongClassificationForest\n",
    "from proglearn.deciders import SimpleArgmaxAverage, KNNClassificationDecider\n",
    "from proglearn.transformers import TreeClassificationTransformer, NeuralClassificationTransformer\n",
    "from proglearn.voters import TreeClassificationVoter, KNNClassificationVoter\n",
    "from proglearn.sims import generate_gaussian_parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-2044709e9905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0my_xor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_xor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_replace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_xor\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mX_xor_tmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_xor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_xor_tmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_xor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_xor_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "X_xor, y_xor = generate_gaussian_parity(n_samples=1000)\n",
    "X_xor_tmp = X_xor\n",
    "\n",
    "indices = np.where((y_xor==0))[0]\n",
    "to_replace = np.random.permutation(indices)[:int(indices.size * 0.9)]\n",
    "\n",
    "X_xor = np.delete(X_xor, to_replace, axis=0)\n",
    "y_xor = np.delete(y_xor, to_replace, axis=0)\n",
    "\n",
    "temp = np.where(X_xor == X_xor_tmp[~to_replace][0,:])[0][0]\n",
    "print(X_xor[temp,:], X_xor_tmp[~to_replace][0,:])\n",
    "print(X_xor.dtype, X_xor_tmp.dtype)\n",
    "\n",
    "colors = sns.color_palette('Dark2', n_colors=2)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "clr = [colors[i] for i in y_xor]\n",
    "ax.scatter(X_xor[:, 0], X_xor[:, 1], c=clr, s=50)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "ax.set_title('Gaussian XOR', fontsize=30)\n",
    "# ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_BTE(samples_task_1, samples_task_2, n_test, n_trees, max_depth, corr,\n",
    "                   means_1, means_2,k_neighbors, acorn=None):\n",
    "    \n",
    "    # See if the sample sizes for both training sets are given.\n",
    "    if samples_task_1 == 0 and samples_task_2 == 0:\n",
    "        raise ValueError(\"Wake up and provide samples to train!!!\")\n",
    "\n",
    "    # If acorn is specified, set random seed to it.\n",
    "    if acorn != None:\n",
    "        np.random.seed(acorn)\n",
    "\n",
    "    # Initialize array for storing errors, task 1, and task 2.\n",
    "    errors = np.zeros((len(means_2)+1), dtype=float)\n",
    "\n",
    "    # Initialize the transformer type and arguments.\n",
    "    default_transformer_class = TreeClassificationTransformer\n",
    "    default_transformer_kwargs = {\"kwargs\": {\"max_depth\": max_depth}}\n",
    "\n",
    "    # Initialize the voter type and arguments.\n",
    "    default_voter_class = TreeClassificationVoter\n",
    "    default_voter_kwargs = {}\n",
    "\n",
    "    # Initialize the decider type and arguments.\n",
    "    default_decider_class = KNNClassificationDecider\n",
    "    default_decider_kwargs = {\"classes\" : np.arange(2), \"k\": k_neighbors}\n",
    "\n",
    "    # Initialize the progressive learner using the transformer, voter and decider classes.\n",
    "    progressive_learner = LifelongClassificationForest(default_transformer_class = default_transformer_class, \n",
    "                                                       default_transformer_kwargs = default_transformer_kwargs,\n",
    "                                                       default_voter_class = default_voter_class,\n",
    "                                                       default_voter_kwargs = default_voter_kwargs,\n",
    "                                                       default_decider_class = default_decider_class,\n",
    "                                                       default_decider_kwargs = default_decider_kwargs)\n",
    "    \n",
    "    # Create the datasets with the Gaussian mean for task 1.\n",
    "    X_task1, y_task1 = generate_gaussian_parity(samples_task_1)\n",
    "    indices = np.where((y_task1==0))[0]\n",
    "    to_replace = np.random.permutation(indices)[:int(indices.size * 0.9)]\n",
    "    X_task1 = np.delete(X_task1, to_replace, axis=0)\n",
    "    y_task1 = np.delete(y_task1, to_replace, axis=0)\n",
    "    X_task1 = X_task1 - means_1\n",
    "\n",
    "    test_task1, test_label_task1 = generate_gaussian_parity(n_test)\n",
    "    indices = np.where((test_label_task1==0))[0]\n",
    "    to_replace = np.random.permutation(indices)[:int(indices.size * 0.9)]\n",
    "    test_task1 = np.delete(test_task1, to_replace, axis=0)\n",
    "    test_label_task1 = np.delete(test_label_task1, to_replace, axis=0)\n",
    "    test_task1 = test_task1 - means_1\n",
    "\n",
    "    # Add a task for the task 1, predict the probabilities and add the MSE to the error array.\n",
    "    progressive_learner.add_task(X_task1, y_task1)\n",
    "    predicted_Z1 = progressive_learner.predict(test_task1, task_id=0)\n",
    "    errors[0] = np.mean(predicted_Z1 == test_label_task1)\n",
    "   \n",
    "    # Then, add the transformer trained on task 2, predict and add the MSE to the error array.\n",
    "    for i in range(len(means_2)):\n",
    "        X_task2,y_task2 = generate_gaussian_parity(samples_task_2)\n",
    "        indices = np.where((y_task2==0))[0]\n",
    "        to_replace = np.random.permutation(indices)[:int(indices.size * 0.9)]\n",
    "        X_task2 = np.delete(X_task2, to_replace, axis=0)\n",
    "        y_task2 = np.delete(y_task2, to_replace, axis=0)\n",
    "        \n",
    "        X_task2 = X_task2 - means_2[i]\n",
    "        \n",
    "        progressive_learner.add_transformer(X_task2, y_task2)\n",
    "        predicted_transformer_Z1 = progressive_learner.predict(test_task1, task_id=0)\n",
    "        errors[i+1] = np.mean(predicted_transformer_Z1 == test_label_task1)\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the tree parameters.\n",
    "mc_rep = 250\n",
    "n_test = 100\n",
    "n_trees = 10\n",
    "n_sample_size = 100\n",
    "max_depth = 10\n",
    "\n",
    "# Set up the data parameters.\n",
    "corr = 0\n",
    "means_1 = [(12,12)]\n",
    "means_2 = [(-4,-4),(-3,-3),(-2,-2),(-1,-1),(0,0),(1,1),(2,2),(3,3),(4,4),\n",
    "          (5,5),(6,6),(7,7),(8,8),(9,9),(10,10),(11,11),(12,12)]\n",
    "means_2.reverse()\n",
    "k_neighbors = [3,5,9,17,33]\n",
    "\n",
    "# Set up sample sizes.\n",
    "samples_task_1 = 100\n",
    "samples_task_2 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LifelongClassificationForest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\shizh\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\shizh\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\shizh\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\shizh\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\joblib\\parallel.py\", line 253, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\shizh\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\joblib\\parallel.py\", line 253, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-33-01bc40ba6f4d>\", line 28, in experiment_BTE\nNameError: name 'LifelongClassificationForest' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-c5ae9a7f3eda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             delayed(experiment_BTE)(\n\u001b[0;32m     13\u001b[0m                 \u001b[0msamples_task_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_task_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trees\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 max_depth, corr, means_1[0], means_2, n1) for _ in range(mc_rep)\n\u001b[0m\u001b[0;32m     15\u001b[0m             )\n\u001b[0;32m     16\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\proglearn\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LifelongClassificationForest' is not defined"
     ]
    }
   ],
   "source": [
    "# Initiate error arrays\n",
    "mean_error_bte = np.zeros((len(k_neighbors), len(means_1) + len(means_2)))\n",
    "std_error_bte = np.zeros((len(k_neighbors), len(means_1) + len(means_2)))\n",
    "\n",
    "# Initiate transfer efficiency arrays\n",
    "mean_bte = np.zeros((len(k_neighbors), len(means_1) + len(means_2)))\n",
    "\n",
    "for i, n1 in enumerate(k_neighbors):\n",
    "    # Create the error.\n",
    "    error = np.array(\n",
    "        Parallel(n_jobs=-1, verbose=1)(\n",
    "            delayed(experiment_BTE)(\n",
    "                samples_task_1, samples_task_2, n_test, n_trees, \n",
    "                max_depth, corr, means_1[0], means_2, n1) for _ in range(mc_rep)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    mean_error_bte[i] = np.mean(error, axis=0)\n",
    "    mean_bte[i] = mean_error_bte[i,0] / mean_error_bte[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty Euclidean distance.\n",
    "ran = np.arange((mean_bte).shape[1])\n",
    "labels = ['k=3','k=5','k=9','k=17','k=33']\n",
    "\n",
    "# Plot the BTEs\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.plot(ran, mean_bte[0], ls=\"-\", lw=3, marker='o')\n",
    "ax.plot(ran, mean_bte[1], ls=\"-\", lw=3, marker='o')\n",
    "ax.plot(ran, mean_bte[2], ls=\"-\", lw=3, marker='o')\n",
    "ax.plot(ran, mean_bte[3], ls=\"-\", lw=3, marker='o')\n",
    "ax.plot(ran, mean_bte[4], ls=\"-\", lw=3, marker='o')\n",
    "\n",
    "ax.set_ylabel(\"Backward Transfer Efficiency wrt Task 1\", fontsize=20)\n",
    "ax.legend(labels, loc=\"upper left\", fontsize=16, frameon=True)\n",
    "ax.set_xlabel(\"Task Number\", fontsize=20)\n",
    "ax.axvline(x=0, c=\"gray\", linewidth=1.5, linestyle=\"dashed\")\n",
    "ax.axhline(y=1, c=\"gray\", linewidth=1.5, linestyle=\"dashed\")\n",
    "ax.set_xticks(ran)\n",
    "ax.set_title('Setting 3', fontsize=20)\n",
    "\n",
    "right_side = ax.spines[\"right\"]\n",
    "right_side.set_visible(False)\n",
    "top_side = ax.spines[\"top\"]\n",
    "top_side.set_visible(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
