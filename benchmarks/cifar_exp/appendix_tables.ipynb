{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "\n",
    "### MAIN HYPERPARAMS ###\n",
    "ntrees = 0\n",
    "slots = 10\n",
    "shifts = 6\n",
    "alg_num = 1\n",
    "task_num = 10\n",
    "model = \"dnn\"\n",
    "########################\n",
    "\n",
    "#%%\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def get_fte_bte(err, single_err, ntrees):\n",
    "    bte = [[] for i in range(10)]\n",
    "    te = [[] for i in range(10)]\n",
    "    fte = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        for j in range(i,10):\n",
    "            #print(err[j][i],j,i)\n",
    "            bte[i].append(err[i][i]/err[j][i])\n",
    "            te[i].append(single_err[i]/err[j][i])\n",
    "                \n",
    "    for i in range(10):\n",
    "        #print(single_err[i],err[i][i])\n",
    "        fte.append(single_err[i]/err[i][i])\n",
    "            \n",
    "            \n",
    "    return fte,bte,te\n",
    "\n",
    "def calc_mean_bte(btes,task_num=10,reps=6):\n",
    "    mean_bte = [[] for i in range(task_num)]\n",
    "\n",
    "\n",
    "    for j in range(task_num):\n",
    "        tmp = 0\n",
    "        for i in range(reps):\n",
    "            tmp += np.array(btes[i][j])\n",
    "        \n",
    "        tmp=tmp/reps\n",
    "        mean_bte[j].extend(tmp)\n",
    "            \n",
    "    return mean_bte     \n",
    "\n",
    "def calc_mean_te(tes,task_num=10,reps=6):\n",
    "    mean_te = [[] for i in range(task_num)]\n",
    "\n",
    "    for j in range(task_num):\n",
    "        tmp = 0\n",
    "        for i in range(reps):\n",
    "            tmp += np.array(tes[i][j])\n",
    "        \n",
    "        tmp=tmp/reps\n",
    "        mean_te[j].extend(tmp)\n",
    "            \n",
    "    return mean_te \n",
    "\n",
    "def calc_mean_fte(ftes,task_num=10,reps=6):\n",
    "    fte = np.asarray(ftes)\n",
    "    \n",
    "    return list(np.mean(np.asarray(fte_tmp),axis=0))\n",
    "\n",
    "def calc_mean_err(err,task_num=10,reps=6):\n",
    "    mean_err = [[] for i in range(task_num)]\n",
    "\n",
    "\n",
    "    for j in range(task_num):\n",
    "        tmp = 0\n",
    "        for i in range(reps):\n",
    "            tmp += np.array(err[i][j])\n",
    "        \n",
    "        tmp=tmp/reps\n",
    "        #print(tmp)\n",
    "        mean_err[j].extend([tmp])\n",
    "            \n",
    "    return mean_err     \n",
    "\n",
    "#%%\n",
    "reps = slots*shifts\n",
    "\n",
    "btes = [[] for i in range(task_num)]\n",
    "ftes = [[] for i in range(task_num)]\n",
    "tes = [[] for i in range(task_num)]\n",
    "err_ = [[] for i in range(task_num)]\n",
    "\n",
    "te_tmp = [[] for _ in range(reps)]\n",
    "bte_tmp = [[] for _ in range(reps)]\n",
    "fte_tmp = [[] for _ in range(reps)]\n",
    "err_tmp = [[] for _ in range(reps)]\n",
    "\n",
    "count = 0   \n",
    "for slot in range(slots):\n",
    "    for shift in range(shifts):\n",
    "        filename = 'result/'+model+str(ntrees)+'_'+str(shift+1)+'_'+str(slot)+'.pickle'\n",
    "        multitask_df, single_task_df = unpickle(filename)\n",
    "\n",
    "        err = [[] for _ in range(10)]\n",
    "\n",
    "        for ii in range(10):\n",
    "            err[ii].extend(\n",
    "             1 - np.array(\n",
    "                 multitask_df[multitask_df['base_task']==ii+1]['accuracy']\n",
    "             )\n",
    "            )\n",
    "        single_err = 1 - np.array(single_task_df['accuracy'])\n",
    "        fte, bte, te = get_fte_bte(err,single_err,ntrees)\n",
    "    \n",
    "        err_ = [[] for i in range(task_num)]\n",
    "        for i in range(task_num):\n",
    "            for j in range(task_num-i):\n",
    "                #print(err[i+j][i])\n",
    "                err_[i].append(err[i+j][i])\n",
    "            \n",
    "        te_tmp[count].extend(te)\n",
    "        bte_tmp[count].extend(bte)\n",
    "        fte_tmp[count].extend(fte)\n",
    "        err_tmp[count].extend(err_)\n",
    "        count+=1\n",
    "    \n",
    "te = calc_mean_te(te_tmp,reps=reps)\n",
    "bte = calc_mean_bte(bte_tmp,reps=reps)\n",
    "fte = calc_mean_fte(fte_tmp,reps=reps)\n",
    "error = calc_mean_err(err_tmp,reps=reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_te_per_rep = [[np.mean(te_tmp[rep][i]) for i in range(len(te))] for rep in range(reps)]\n",
    "mean_te_per_rep = np.mean(flat_te_per_rep, axis = 1)\n",
    "min_te_per_rep = np.min(flat_te_per_rep, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean TE: (1.2151131332308263 +- 0.014993975109554573)\n",
      "Min TE: (1.094692661815922 +- 0.0315075161426492)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean TE: ({} +- {})\".format(np.mean(mean_te_per_rep), np.std(mean_te_per_rep)))\n",
    "print(\"Min TE: ({} +- {})\".format(np.mean(min_te_per_rep), np.std(min_te_per_rep)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_fte_task_10_per_rep = [fte_tmp[rep][9] for rep in range(reps)]\n",
    "task_bte_task_1_per_rep = [bte_tmp[rep][0][9] for rep in range(reps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean FTE(Task 10): (1.363911173747584 +- 0.06092776038764332)\n",
      "Mean BTE(Task 1): (1.183417340202393 +- 0.059798632137465835)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean FTE(Task 10): ({} +- {})\".format(np.mean(task_fte_task_10_per_rep), np.std(task_fte_task_10_per_rep)))\n",
    "print(\"Mean BTE(Task 1): ({} +- {})\".format(np.mean(task_bte_task_1_per_rep), np.std(task_bte_task_1_per_rep)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final TE of Task 0: (1.183417340202393 +- 0.059798632137465835)\n",
      "Final TE of Task 1: (1.1573109953796412 +- 0.0474808924470105)\n",
      "Final TE of Task 2: (1.1693928884540874 +- 0.053910192392614256)\n",
      "Final TE of Task 3: (1.2119055520937985 +- 0.04960775063565548)\n",
      "Final TE of Task 4: (1.1988468581884244 +- 0.05287406679722945)\n",
      "Final TE of Task 5: (1.31790836452783 +- 0.055738539734944095)\n",
      "Final TE of Task 6: (1.2531010506687073 +- 0.07356446960061813)\n",
      "Final TE of Task 7: (1.2020854708865125 +- 0.049530099356080125)\n",
      "Final TE of Task 8: (1.247174618428836 +- 0.046167947227546656)\n",
      "Final TE of Task 9: (1.363911173747584 +- 0.06092776038764332)\n"
     ]
    }
   ],
   "source": [
    "for task in range(task_num):\n",
    "    final_te_of_task_per_rep = [te_tmp[rep][task][-1] for rep in range(reps)]\n",
    "    print(\"Final TE of Task {}: ({} +- {})\".format(task, np.mean(final_te_of_task_per_rep), np.std(final_te_of_task_per_rep)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
